{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base OpenAI Client\n",
    "\n",
    "```python\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8080/openai/v1\",\n",
    "    api_key=\"test\",\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='llama3.2:latest', created=1731215929, object='model', owned_by='library')], object='list')\n",
      "It appears to be one. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8080/openai/v1\",\n",
    "    api_key=\"test\",\n",
    ")\n",
    "\n",
    "print(client.models.list())\n",
    "\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Say this is a test\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3.2:latest\",\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "Error code: 404 - {'error': {'message': 'model \"llama3\" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m### Streaming\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m chat_completion \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mWrite me a pretty short story\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama3\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m chat_completion:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(i\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mdelta\u001b[38;5;241m.\u001b[39mcontent, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/_utils/_utils.py:271\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    269\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    270\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 271\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/resources/chat/completions.py:659\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    609\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    610\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    657\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    658\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 659\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    661\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    664\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    665\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    666\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    680\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    682\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    683\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    684\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    685\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    686\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    688\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    691\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py:1180\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1167\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1168\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1175\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1177\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1178\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1179\u001b[0m     )\n\u001b[0;32m-> 1180\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py:869\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    860\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    861\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    862\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    867\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    868\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 869\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    873\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py:945\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[1;32m    944\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m--> 945\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    946\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    947\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    948\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    949\u001b[0m \u001b[43m        \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    952\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    954\u001b[0m \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    955\u001b[0m \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    956\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mis_closed:\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py:993\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    991\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 993\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    994\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    995\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    996\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    997\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    998\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    999\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/lib/python3.11/site-packages/openai/_base_client.py:960\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    957\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m    959\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 960\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    962\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m    963\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m    964\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    967\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m    968\u001b[0m )\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Error code: 404 - {'error': {'message': 'model \"llama3\" not found, try pulling it first', 'type': 'api_error', 'param': None, 'code': None}}"
     ]
    }
   ],
   "source": [
    "### Streaming\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me a pretty short story\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"llama3.2:latest\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "for i in chat_completion:\n",
    "    print(i.choices[0].delta.content, end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Azure OpenAI Client\n",
    "\n",
    "```python\n",
    "client = AzureOpenAI(\n",
    "    base_url=\"http://localhost:8080/azure\",\n",
    "    api_key=\"test\",\n",
    "    api_version=\"test\",\n",
    ")\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# azureClient = AzureOpenAI(\n",
    "#     base_url=\"http://localhost:8080/azure\",\n",
    "#     api_key=\"test\",\n",
    "#     api_version=\"test\",\n",
    "# )\n",
    "\n",
    "# completion = azureClient.chat.completions.create(\n",
    "#     model=\"gpt-3.5-turbo\",\n",
    "#     messages=[\n",
    "#         {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "#         {\"role\": \"user\", \"content\": \"Hello!\"},\n",
    "#     ],\n",
    "# )\n",
    "# print(completion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boto3 Bedrock Runtime Client\n",
    "\n",
    "```python\n",
    "def _replace_headers(request: AWSRequest, **kwargs):\n",
    "    request.headers = {\"Authorization\": \"Bearer test\"}\n",
    "\n",
    "client = boto3.client(\"bedrock-runtime\", endpoint_url=\"http://localhost:8080/bedrock\")\n",
    "client.meta.events.register(\"before-send.bedrock-runtime.*\", _replace_headers)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "failed to send, dropping 2 traces to intake at http://localhost:8126/v0.5/traces after 3 retries\n"
     ]
    }
   ],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "\n",
    "\n",
    "def _replace_headers(request, **kwargs):\n",
    "    request.headers = {\"Authorization\": \"Bearer test\"}\n",
    "\n",
    "\n",
    "bedrockClient = boto3.client(\n",
    "    \"bedrock-runtime\", endpoint_url=\"http://localhost:8080/bedrock\"\n",
    ")\n",
    "bedrockClient.meta.events.register(\"before-send.bedrock-runtime.*\", _replace_headers)\n",
    "\n",
    "model_id = \"us.meta.llama3-2-1b-instruct-v1:0\"\n",
    "user_message = \"Say 'hi'\"\n",
    "conversation = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [{\"text\": user_message}],\n",
    "    }\n",
    "]\n",
    "\n",
    "try:\n",
    "    # Send the message to the model, using a basic inference configuration.\n",
    "    response = bedrockClient.converse(\n",
    "        modelId=model_id,\n",
    "        messages=conversation,\n",
    "        inferenceConfig={\"maxTokens\": 512, \"temperature\": 0.5, \"topP\": 0.9},\n",
    "    )\n",
    "    response_text = response[\"output\"][\"message\"][\"content\"][0][\"text\"]\n",
    "    print(response_text)\n",
    "\n",
    "except (ClientError, Exception) as e:\n",
    "    print(f\"ERROR: Can't invoke '{model_id}'. Reason: {e}\")\n",
    "    exit(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google Vertex Client\n",
    "\n",
    "```python\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "\n",
    "vertexai.init(\n",
    "    project=os.getenv(\"VERTEX_AI_PROJECT_ID\"),\n",
    "    api_endpoint=\"http://localhost:8080/vertex\",\n",
    ")\n",
    "\n",
    "generative_multimodal_model = GenerativeModel(\"gemini-1.5-flash-002\")\n",
    "response = generative_multimodal_model.generate_content([\"Say hi\"])\n",
    "\n",
    "print(response)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "failed to send, dropping 1 traces to intake at http://localhost:8126/v0.5/traces after 3 retries, 2 additional messages skipped\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"Hi there! üòä How can I help you today?\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 2\n",
      "  candidates_token_count: 11\n",
      "  total_token_count: 13\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"The old lighthouse keeper, Silas, had seen a century of storms lash against the craggy coast of Aethelgard.  His beard, the color of sea foam and spun silver, reached his chest, and his eyes, the faded blue of a winter sky, held\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" the weight of countless sunrises and shipwrecks.  He‚Äôd watched generations of families come and go from the small, wind-bitten village nestled at the foot of the cliffs, each life a fleeting flicker against the enduring backdrop of the sea and the stone. But he‚Äôd never seen a storm\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" quite like this one.\\n\\nIt began subtly, a whisper of unrest in the usually predictable rhythm of the tides. The gulls cried with an unusual urgency, circling lower and lower as if seeking shelter that didn‚Äôt exist.  The sea, normally a vibrant sapphire, turned a bruised, angry purple, churning with\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" a disquieting energy.  Then the wind, a mournful howl at first, escalated into a shrieking banshee, tearing at the stout stone walls of the lighthouse as if determined to dismantle it brick by brick.\\n\\nSilas had lit the lamp early, its beam a defiant finger of gold piercing the gathering\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" gloom. He climbed the winding stairs, his joints protesting with familiar creaks and groans, each step a testament to his long, arduous service. From the lantern room, the view was terrifyingly magnificent.  Waves the size of houses, frothing white at their peaks, crashed against the cliffs, sending plumes of spray\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" that reached halfway up the lighthouse itself. The air was thick with salt and the roar of the storm drowned out all other sounds.\\n\\nHe was alone in the lighthouse, as he usually was.  His apprentice, a young lad named Finn, had been sent to the village to ensure the families there were battened down\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" and safe.  Silas trusted Finn, though the boy was still green, still more land-lover than seaman. But he had a good heart and strong hands, and that was what mattered in Aethelgard.\\n\\nAs the storm raged, Silas found himself thinking not of shipwrecks, though\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" he knew they were inevitable on nights like this, but of stories.  Stories his grandmother had told him when he was a boy huddled by the hearth, stories of sea monsters and mermaids, of drowned cities and phantom ships.  Silly tales for a grown man, he knew, but tonight, with the fury\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" of the ocean battering at his lonely tower, they felt strangely‚Ä¶ real.\\n\\nSuddenly, a sound cut through the storm\\'s cacophony.  Not the crash of waves, nor the shriek of wind, but a different sound, a rhythmic, almost metallic clang.  Confused, Silas peered through the swirling\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" rain and spray.  The beam of the lighthouse lamp swept across the tumultuous water, illuminating fleeting glimpses of churning foam and dark, ominous shapes.  Then he saw it.\\n\\nWrenched against the rocks just below the lighthouse was a vessel unlike any he had ever seen.  It was crafted from a dark, gleaming\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" metal, smooth and strangely organic in its curves.  It was not a ship in the traditional sense; it had no sails, no rigging. It was more like‚Ä¶ a giant, metallic seed pod, split open and battered by the waves.  And from within the wreckage, amidst the swirling foam, something moved.\\n\\nSilas\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \", his heart pounding against his ribs, grabbed his oilskins and his thick rope.  He wasn\\'t young anymore, his bones ached, and the wind threatened to rip him from his feet, but he couldn\\'t just stand by and watch.  He had to try.\\n\\nHe descended the lighthouse stairs, the wind\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" howling at his back, and braced himself against the cliff face. The path down to the rocks was treacherous even on a calm day, tonight it was a suicide mission.  But Silas was a lighthouse keeper, and lighthouse keepers were not cowards.\\n\\nHe battled his way down, clinging to handholds in the rock\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \", the spray soaking him to the bone.  The wind tore at his beard, blinding him with salt and rain.  Finally, he reached the base of the cliffs, the roar of the waves deafening.  He could see the wrecked vessel more clearly now, and the figure clinging to a jagged piece of metal,\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" fighting against the relentless surge.\\n\\nIt was a woman.\\n\\nNot just any woman, but one unlike any Silas had ever encountered. Her skin was pale, almost luminescent in the gloom, and her hair, tangled and wet, shone with an unnatural silver sheen.  Her eyes, when she turned her face towards\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" him, were large and the color of the deepest ocean, reflecting the turmoil around them.  She was clad in garments that seemed to shimmer and shift in the dim light, woven from something that looked like liquid moonlight.\\n\\nHe scrambled towards her, battling against the waves that threatened to sweep him away. He reached out a hand\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \", his calloused fingers closing around hers.  Her skin was cold, almost unnaturally so, but her grip was surprisingly strong.\\n\\n‚ÄúHold on!‚Äù he shouted, his voice barely audible above the storm.  He pulled, straining every muscle in his aging body, and slowly, painstakingly, dragged her towards the\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" relative safety of the cliff face.  He secured her to a rocky outcrop with his rope, then pulled her further up, away from the immediate onslaught of the waves.\\n\\nFinally, they were huddled together in a small alcove, partially sheltered from the wind and rain.  The woman was shivering uncontrollably, her breath\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" coming in ragged gasps.  Silas, soaked and exhausted, felt a surge of something he hadn\\'t felt in years ‚Äì adrenaline, and a strange sense of purpose.\\n\\nHe looked at her more closely in the dim light. She was undeniably beautiful, in a way that felt otherworldly.  Her features were delicate\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \", almost ethereal, and her eyes held a depth of sadness that belied her youthful appearance.  She was injured; a deep gash bled slowly on her arm.\\n\\n‚ÄúCan you understand me?‚Äù Silas asked, his voice hoarse.\\n\\nShe looked at him, her eyes unfocused for a moment, then\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" slowly nodded.  Her voice, when she spoke, was soft and melodic, like the chiming of distant bells, but with a strange undertone, almost‚Ä¶ watery.\\n\\n‚ÄúYes,‚Äù she whispered, her words barely audible. ‚ÄúThank you.‚Äù  She spoke in his language, Aethelgardian, though\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" with an accent he couldn\\'t quite place.\\n\\n‚ÄúWho are you?‚Äù Silas asked, his curiosity overriding his caution.\\n\\nShe hesitated, her gaze drifting out to the raging sea.  ‚ÄúI‚Ä¶ I am Lyra,‚Äù she finally said. ‚ÄúAnd I am‚Ä¶ lost.‚Äù\\n\\nSilas helped her back\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" to the lighthouse, a grueling climb in the storm\\'s fury.  He wrapped her in thick blankets and gave her hot tea, watching as the color slowly returned to her cheeks.  She told him her story, or at least, as much as she could remember.\\n\\nShe had been traveling, she said, across\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" the Great Ocean, in her‚Ä¶ vessel.  She spoke of a journey spanning vast distances, through stars and currents beyond human comprehension.  She spoke of her people, the ‚ÄòAethel Maris,‚Äô the Sea-Born, who lived in realms beneath the waves, realms of coral castles and shimmering kelp forests.  \"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"She spoke of a mission, a quest for something lost, something vital to her people. But the storm, the crash‚Ä¶ it had stolen her memories, left her adrift in a world she didn\\'t understand.\\n\\nSilas listened, his old eyes wide with wonder and disbelief.  He‚Äôd heard sailors\\'\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" tales of mermaids and underwater kingdoms, but he\\'d always dismissed them as fanciful yarns.  Now, looking at Lyra, at her strange clothing, at the remnants of her metallic vessel wrecked upon the rocks below, he began to wonder if perhaps, just perhaps, there was more to the old stories than he‚Äô\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"d ever imagined.\\n\\nHe didn‚Äôt press her for details she couldn‚Äôt remember. Instead, he focused on tending to her wounds, on offering her comfort and shelter.  He knew Finn would be worried sick if he didn‚Äôt return to the village soon, but he couldn‚Äôt leave Lyra alone. Not\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" yet.\\n\\nThe storm raged for three days and nights, an unrelenting assault on the coast.  During that time, Silas and Lyra were trapped in the lighthouse together.  They talked, hesitantly at first, then with increasing openness.  Silas told her about Aethelgard, about the rhythms of life in\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" the village, about the history etched into the stones of the lighthouse itself. Lyra, in turn, shared fragments of her world, of shimmering cities beneath the waves, of creatures that sang songs of starlight, of a deep, ancient magic that pulsed through the oceans.\\n\\nHe learned that she was not a mermaid,\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" not in the traditional sense.  The Aethel Maris were beings of water and light, adapted to the deep ocean, but they were not fish-tailed monsters of legend.  They were intelligent, sophisticated, and deeply connected to the natural world in ways humans had long forgotten.  Her vessel, she explained, was a bio\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \"-engineered craft, grown rather than built, capable of traversing both water and‚Ä¶ other realms.  She couldn\\'t explain it fully, her memories were too fragmented, but she hinted at dimensions beyond human perception, at a universe far vaster and more wondrous than Silas could have ever conceived.\\n\\nAs the storm finally began\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" to abate, the wind sighing rather than screaming, the waves receding from their frenzied heights, Silas realized something profound had changed within him.  He, the stoic lighthouse keeper, who had always believed in the tangible, the measurable, was suddenly confronted with the impossible, the magical.  And he wasn\\'t afraid\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \". He was‚Ä¶ captivated.\\n\\nFinn returned to the lighthouse, his face etched with worry.  He was astonished to find not just Silas, safe and sound, but also a beautiful, enigmatic woman in his care.  Silas introduced Lyra, simply saying she was a traveler who had been shipwrecked in the storm\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \".  He didn‚Äôt reveal the full truth, not yet. He wanted to protect her, to understand more before the village tongues started wagging.\\n\\nAs the days passed, Lyra slowly regained some of her strength.  She spent hours on the cliffs, gazing out at the sea, as if listening for\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" a call only she could hear.  She was quiet, often lost in thought, but she was also kind and gentle.  She helped Silas with his chores, her strange, slender fingers surprisingly adept at mending nets and polishing the lighthouse lamp.  She learned about human ways, about fire and cooking, about the simple\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" rhythms of village life.\\n\\nThe villagers, naturally, were curious.  Whispers circulated about the strange woman who had appeared with the storm. Some called her a siren, others a sea spirit.  Children, braver than their parents, would leave small gifts for her at the lighthouse door ‚Äì seashells, smooth stones, wildflowers\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" plucked from the cliffside.\\n\\nLyra seemed to appreciate their kindness, but she remained distant, her gaze always drawn back to the ocean.  Silas could see the yearning in her eyes, the silent plea for something lost, something she desperately needed to find.\\n\\nOne evening, as the sun dipped below the horizon\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \", painting the sky in hues of orange and purple, Lyra turned to Silas, her ocean-deep eyes filled with a new resolve.\\n\\n‚ÄúSilas,‚Äù she said, her voice firm. ‚ÄúI need to return to the sea.  I feel‚Ä¶ a pull.  Something is calling me.‚Äù\\n\\nSilas felt\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" a pang of sadness.  He had grown fond of Lyra, of her quiet presence, of her otherworldly wisdom.  He knew she couldn‚Äôt stay in Aethelgard forever, but he had hoped‚Ä¶ he wasn\\'t sure what he had hoped.\\n\\n‚ÄúDo you remember‚Ä¶ anything more?‚Äù he\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" asked. ‚ÄúAbout your mission?‚Äù\\n\\nLyra closed her eyes for a moment, her brow furrowed in concentration.  Then, slowly, she nodded.  ‚ÄúYes,‚Äù she whispered. ‚ÄúFragments.  I was searching for‚Ä¶ a key.  An artifact of power.  Something that was stolen from my\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" people, long ago.  Something‚Ä¶ that must be returned.‚Äù\\n\\n‚ÄúA key?‚Äù Silas repeated, intrigued. ‚ÄúWhat kind of key?‚Äù\\n\\nLyra opened her eyes, and in their depths, Silas saw a glimmer of hope, and a flicker of fear.  ‚ÄúI‚Ä¶ I don‚Äôt know exactly\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \",‚Äù she confessed. ‚ÄúBut I know it is connected to the ocean.  To the deep currents.  And‚Ä¶ I think it is here.‚Äù\\n\\nSilas looked out at the calm sea, now shimmering under the twilight sky.  Here? In Aethelgard?  It seemed impossible, yet‚Ä¶ after\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" everything he had witnessed, he was no longer so certain of what was impossible.\\n\\n‚ÄúThen we will search,‚Äù Silas declared, his voice surprisingly strong.  ‚ÄúWe will search together.‚Äù\\n\\nAnd so, the old lighthouse keeper and the sea-born woman embarked on a new quest, not to warn ships away from\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" danger, but to delve into the mysteries of the deep, to uncover a lost artifact, and to heal a wound that spanned worlds.  Silas, with his knowledge of the coast, his understanding of the tides and currents, and Lyra, with her innate connection to the ocean and her fragmented memories, became an\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" unlikely pair, bound by a shared purpose, venturing into the unknown, guided by the whispers of the sea and the flickering flame of hope in the old lighthouse lantern.  Their journey had just begun, and the ocean, vast and ancient, held secrets yet to be revealed, secrets that could change Aethelgard,\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n",
      "candidates {\n",
      "  content {\n",
      "    role: \"model\"\n",
      "    parts {\n",
      "      text: \" and perhaps, the very fabric of their worlds, forever.\"\n",
      "    }\n",
      "  }\n",
      "  finish_reason: STOP\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 6\n",
      "  candidates_token_count: 2898\n",
      "  total_token_count: 2904\n",
      "}\n",
      "model_version: \"gemini-2.0-flash-thinking-exp-01-21\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import vertexai\n",
    "from vertexai.preview.generative_models import GenerativeModel\n",
    "\n",
    "vertexai.init(\n",
    "    project=os.getenv(\"VERTEX_AI_PROJECT_ID\", \"encrypted-llm\"),\n",
    "    api_endpoint=\"http://0.0.0.0:8080/vertex\",\n",
    "    api_transport=\"rest\",\n",
    ")\n",
    "\n",
    "generative_multimodal_model = GenerativeModel(\"gemini-2.0-flash-thinking-exp-01-21\")\n",
    "response = generative_multimodal_model.generate_content([\"Say hi\"])\n",
    "\n",
    "print(response)\n",
    "\n",
    "\n",
    "response = generative_multimodal_model.generate_content(\n",
    "    [\"WRite me a long story\"], stream=True\n",
    ")\n",
    "for i in response:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ELL Framework Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ell\n",
    "from pydantic import Field\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "ell.init(verbose=True)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "BEDROCK CLIENT\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "@ell.simple(model=\"us.meta.llama3-2-1b-instruct-v1:0\", client=bedrockClient)\n",
    "def bedrock_chat(prompt: str) -> str:\n",
    "    return prompt\n",
    "\n",
    "\n",
    "print(f'Bedrock \\n\\n {bedrock_chat(\"Hello, how are you?\")}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "OpenAI Client\n",
    "\"\"\"\n",
    "\n",
    "@ell.simple(model=\"gpt-4o-mini\", max_tokens=10, client=client)\n",
    "def openai_client(prompt: str) -> str:\n",
    "    return prompt\n",
    "\n",
    "\n",
    "print(f'OpenAI \\n\\n {openai_client(\"Hello, how are you?\")}\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "TOOL USAGE\n",
    "\"\"\"\n",
    "\n",
    "@ell.tool()\n",
    "def get_html_content(\n",
    "    url: str = Field(\n",
    "        description=\"The URL to get the HTML content of. Never include the protocol (like http:// or https://)\"\n",
    "    ),\n",
    "):\n",
    "    \"\"\"Get the HTML content of a URL.\"\"\"\n",
    "    response = requests.get(\"https://\" + url)\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "    return soup.get_text()[:100]\n",
    "\n",
    "\n",
    "# OpenAI Client\n",
    "@ell.complex(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    tools=[get_html_content],\n",
    "    client=client,\n",
    ")\n",
    "def openai_get_website_content(website: str) -> str:\n",
    "    return f\"Tell me what's on {website}\"\n",
    "\n",
    "\n",
    "print(\"OpenAI Client Tool Use\\n\\n\")\n",
    "output = openai_get_website_content(\"new york times front page\")\n",
    "if output.tool_calls:\n",
    "    print(output.tool_calls[0]())\n",
    "\n",
    "\n",
    "# Bedrock Client\n",
    "@ell.complex(\n",
    "    model=\"anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    tools=[get_html_content],\n",
    "    client=bedrockClient,\n",
    ")\n",
    "def bedrock_get_website_content(website: str) -> str:\n",
    "    \"\"\"You are an agent that can summarize the contents of a website.\"\"\"\n",
    "    return f\"Tell me what's on {website}\"\n",
    "\n",
    "\n",
    "print(\"\\n\\nBedrock Client Tool Use\\n\\n\")\n",
    "output = bedrock_get_website_content(\"new york times front page\")\n",
    "if output.tool_calls:\n",
    "    print(output.tool_calls[0]())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8080/openai-proxy/v1\",\n",
    "    api_key=\"test\",\n",
    ")\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Whats up dog?\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"bedrock/us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    stream=False,\n",
    ")\n",
    "\n",
    "print(chat_completion)\n",
    "print(chat_completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI, AzureOpenAI\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8080/openai-proxy/v1\",\n",
    "    api_key=\"test\",\n",
    ")\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=[\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Write me a pretty short story\",\n",
    "        }\n",
    "    ],\n",
    "    model=\"bedrock/us.anthropic.claude-3-sonnet-20240307-v2:0\",\n",
    "    stream=True,\n",
    ")\n",
    "\n",
    "# for i in chat_completion:\n",
    "#     print(i)\n",
    "# print()\n",
    "\n",
    "\n",
    "for i in chat_completion:\n",
    "    print(i.choices[0].delta.content, end=\"\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"type\": \"function\",\n",
    "        \"function\": {\n",
    "            \"name\": \"get_delivery_date\",\n",
    "            \"description\": \"Get the delivery date for a customer's order. Call this whenever you need to know the delivery date, for example when a customer asks 'Where is my package'\",\n",
    "            \"parameters\": {\n",
    "                \"type\": \"object\",\n",
    "                \"properties\": {\n",
    "                    \"order_id\": {\n",
    "                        \"type\": \"string\",\n",
    "                        \"description\": \"The customer's order ID.\",\n",
    "                    },\n",
    "                },\n",
    "                \"required\": [\"order_id\"],\n",
    "                \"additionalProperties\": False,\n",
    "            },\n",
    "        },\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": \"Hi, can you tell me the delivery date for my order?\"}\n",
    "]\n",
    "\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"http://localhost:8080/openai-proxy/v1\",\n",
    "    api_key=\"test\",\n",
    ")\n",
    "# chat_completion = client.chat.completions.create(\n",
    "#     model=\"bedrock/us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "#     messages=messages,\n",
    "#     # tools=tools,\n",
    "#     stream=False\n",
    "# )\n",
    "chat_completion = client.chat.completions.create(\n",
    "    messages=messages,\n",
    "    model=\"bedrock/us.anthropic.claude-3-haiku-20240307-v1:0\",\n",
    "    stream=False,\n",
    "    tools=tools,\n",
    "    tool_choice=\"required\",\n",
    ")\n",
    "print(chat_completion.choices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(client.models.list())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
