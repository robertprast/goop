services:
  # open-webui-pipelines:
  #   pull_policy: always
  #   image: ghcr.io/open-webui/pipelines:main
  #   container_name: pipelines
  #   volumes:
  #       - pipelines:/app/pipelines
  #   extra_hosts:
  #     - host.docker.internal:host-gateway
  #   restart: unless-stopped
  #   ports:
  #     - 9099:9099

  open-webui:
    # image: ghcr.io/open-webui/open-webui:main
    pull_policy: always
    build:
      context: .
      dockerfile: Dockerfile
    container_name: open-webui
    volumes:
      - open-webui-vol:/app/backend/data
    ports:
      - ${OPEN_WEBUI_PORT-3000}:8080
    environment:
      - 'OLLAMA_BASE_URL=http://ollama:11434'
      - 'WEBUI_SECRET_KEY='
      - 'OPENAI_API_BASE_URL=http://host.docker.internal:8080/openai_schema-engine_proxy/v1'
      - 'OPENAI_API_KEY=0p3n-w3bu!'
      - 'WEBUI_AUTH=false'
      - 'SCARF_NO_ANALYTICS=true'
      - 'DO_NOT_TRACK=true'
      - 'ANONYMIZED_TELEMETRY=false'
    extra_hosts:
      - host.docker.internal:host-gateway
    restart: unless-stopped

volumes:
  open-webui-vol: {}
  # pipelines: {}
